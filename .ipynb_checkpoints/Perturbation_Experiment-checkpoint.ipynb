{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36692\n",
      "183831\n"
     ]
    }
   ],
   "source": [
    "class DataSets:\n",
    "    base_path = 'data/'\n",
    "    CORA =     {'path': 'cora/cora.cites', 'sep': '\\t'}\n",
    "    FACEBOOK = {'path': 'facebook/facebook_combined.txt', 'sep': ' '}\n",
    "    ENRON_EMAILS = {'path': 'enron/email-Enron.txt', 'sep': '\\t'}\n",
    "\n",
    "    # returns an networkx graph object representing the dataset\n",
    "    # if lcc is true, it\n",
    "    @classmethod\n",
    "    def get_undirected_networkx_graph(cls, dataset, lcc=True):\n",
    "        path = cls.base_path + dataset['path']\n",
    "        separator = dataset['sep']\n",
    "        edgelist = pd.read_csv(path, sep=separator, names=['target', 'source'], comment='#')\n",
    "        G = nx.from_pandas_edgelist(edgelist)\n",
    "        if lcc == True:\n",
    "            gs = [G.subgraph(c) for c in nx.connected_components(G)]\n",
    "            G = max(gs, key=len)\n",
    "        return G\n",
    "        \n",
    "G = DataSets.get_undirected_networkx_graph(DataSets.ENRON_EMAILS, lcc=False)\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphProperties:\n",
    "    DEGREE_CENTRALITY = (1, 'Degree Centrality')\n",
    "    BETWEENNESS_CENTRALITY = (2, 'Betweenness Centrality')\n",
    "    \n",
    "    @classmethod\n",
    "    def get_graph_property(cls, G, prop):\n",
    "        if(prop == 1):\n",
    "            return cls._average_degree_centrality(G)\n",
    "        if(prop == 2):\n",
    "            return cls._average_betweenness_centrality(G)\n",
    "      \n",
    "    def _average_betweenness_centrality(G):\n",
    "        return sum(dict(nx.betweenness_centrality(G)).values())/float(len(G))\n",
    "    \n",
    "\n",
    "    def _average_degree_centrality(G):\n",
    "        return sum(dict(nx.degree_centrality(G)).values())/float(len(G))             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphModifier:\n",
    "    G = None\n",
    "    H = None\n",
    "    \n",
    "    ADD_RANDOM = 1\n",
    "    REMOVE_RANDOM = 2\n",
    "    REMOVE_ORDERED = 3\n",
    "    \n",
    "    def __init__(self, graph):\n",
    "        self.G = graph.copy()\n",
    "        \n",
    "    def perturb_graph(self, perturb_type, num_edges, offset=None):\n",
    "        if perturb_type == 1:\n",
    "            return self._add_random_unweighted_edges(num_edges)\n",
    "        if perturb_type == 2:\n",
    "            return self._remove_random_edges(num_edges)\n",
    "        if perturb_type == 3:\n",
    "            return self._remove_ordered_edges(num_edges, offset)\n",
    "        \n",
    "        \n",
    "    # returns graph with edges removed, but leaves self.graph unchanged\n",
    "    def _remove_random_edges(self, num_edges):\n",
    "        self.H = self.G.copy()\n",
    "        prev_edges = []\n",
    "        for i in range(0, num_edges):\n",
    "            total_edges = self.H.number_of_edges()\n",
    "            rand_edge_index = random.choice([x for x in range(total_edges) if x not in prev_edges]) # SLOW\n",
    "            prev_edges.append(rand_edge_index)\n",
    "            edge_tuple = list(self.H.edges)[rand_edge_index]\n",
    "            self.H.remove_edge(*edge_tuple)\n",
    "        return self.H\n",
    "    \n",
    "    def _remove_ordered_edges(self, num_edges, offset):\n",
    "        self.H = self.G.copy()\n",
    "        start_index = num_edges*offset\n",
    "        end_index = start_index + num_edges\n",
    "        if end_index > self.G.number_of_edges(): # if out of bounds\n",
    "            return False\n",
    "        edge_list = list(self.G.edges)\n",
    "        edges_to_remove = edge_list[start_index:end_index]\n",
    "        for edge_tuple in edges_to_remove:\n",
    "            self.H.remove_edge(*edge_tuple)\n",
    "        return self.H\n",
    "    \n",
    "    def _add_random_unweighted_edges(self, num_edges):\n",
    "        self.H = self.G.copy()\n",
    "        for i in range(num_edges):\n",
    "            new_edge = self.__generate_random_edge()\n",
    "            self.H.add_edge(*new_edge)\n",
    "        return self.H\n",
    "            \n",
    "                \n",
    "    # Randomly generates a unique edge for self.H\n",
    "    def __generate_random_edge(self):\n",
    "        edge_list = list(self.H.edges())\n",
    "        node_list =  list(self.H.nodes())\n",
    "        total_nodes = len(node_list)\n",
    "        u_index, v_index = random.sample(range(0, total_nodes), 2)\n",
    "        u, v = node_list[u_index], node_list[v_index]\n",
    "        while (u, v) in edge_list or (v, u) in edge_list:\n",
    "            u_index, v_index = random.sample(range(0, total_nodes), 2)\n",
    "            u, v = node_list[u_index], node_list[v_index]\n",
    "        return (u, v)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run with DEGREE CENTRALITY and ADDING EDGES (randomly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Centrality  of the spanner of unperturbed graph\n",
      "0.0016365503811920747 \n",
      "\n",
      "Degree Centrality  of the spanner of perturbed graph\n",
      "Perturbation:  1000  edges are randomly added\n",
      "0.00195472351014291\n",
      "0.0019553715205888425\n",
      "0.0019547235101429142\n",
      "0.0019547235101429164\n",
      "0.0019550475153658703\n"
     ]
    }
   ],
   "source": [
    "graph_property = GraphProperties.DEGREE_CENTRALITY\n",
    "perturb_type = GraphModifier.ADD_RANDOM\n",
    "\n",
    "# Sparsify unperturbed graph and print property\n",
    "Gsparse = nx.spanner(G,3,seed=1)\n",
    "prop = GraphProperties.get_graph_property(Gsparse, graph_property[0])\n",
    "print(graph_property[1], \" of the spanner of unperturbed graph\")\n",
    "print(prop, '\\n')\n",
    "\n",
    "# Perturb graph, then sparsify, then print property\n",
    "num_trials = 5\n",
    "num_edges = 1000\n",
    "print(graph_property[1], \" of the spanner of perturbed graph\")\n",
    "print(\"Perturbation: \", num_edges, \" edges are randomly added\")\n",
    "modifier = GraphModifier(G)\n",
    "for i in range(num_trials):\n",
    "    H = modifier.perturb_graph(perturb_type, num_edges)\n",
    "    Hsparse = nx.spanner(H,3,seed=7)\n",
    "    prop = GraphProperties.get_graph_property(Hsparse, graph_property[0])\n",
    "    print(prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run with DEGREE CENTRALITY and REMOVING EDGES (in order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Centrality  of the spanner of unperturbed graph\n",
      "0.0016339583394083626 \n",
      "\n",
      "Degree Centrality after removing groups of 150 edges\n",
      "0.0015843855402948445\n",
      "0.0015843855402948434\n",
      "0.0015850335507407718\n",
      "0.001585033550740772\n",
      "0.0015843855402948451\n",
      "0.0015843855402948442\n",
      "0.0015843855402948447\n",
      "0.0015850335507407729\n",
      "0.001585357555963737\n",
      "0.0015853575559637372\n",
      "0.0015843855402948447\n",
      "0.0015853575559637357\n",
      "0.0015843855402948442\n",
      "0.0015843855402948436\n",
      "0.0015853575559637368\n",
      "0.0015847095455178081\n",
      "0.0015843855402948445\n",
      "0.0015843855402948438\n",
      "0.0015850335507407718\n",
      "0.0015847095455178077\n",
      "0.0015843855402948442\n",
      "0.0015847095455178068\n",
      "0.001584385540294843\n",
      "0.001584709545517806\n",
      "0.0015853575559637357\n",
      "0.0015856815611866998\n",
      "0.001584709545517806\n",
      "0.001584709545517808\n",
      "0.0015860055664096637\n",
      "0.0015843855402948423\n",
      "0.0015850335507407694\n",
      "0.0015847095455178049\n",
      "0.0015853575559637348\n"
     ]
    }
   ],
   "source": [
    "graph_property = GraphProperties.DEGREE_CENTRALITY\n",
    "perturb_type = GraphModifier.REMOVE_ORDERED\n",
    "\n",
    "# Sparsify unperturbed graph and print property\n",
    "Gsparse = nx.spanner(G,3,seed=7)\n",
    "prop = GraphProperties.get_graph_property(Gsparse, graph_property[0])\n",
    "print(graph_property[1], \" of the spanner of unperturbed graph\")\n",
    "print(prop,'\\n')\n",
    "    \n",
    "# Perturb graph, then sparsify, then print property\n",
    "total_edges = G.number_of_edges()\n",
    "num_to_remove = 150\n",
    "num_rounds = total_edges//num_to_remove\n",
    "print(\"Degree Centrality after removing groups of\", num_to_remove, \"edges\"  )\n",
    "modifier = GraphModifier(G)\n",
    "for i in range(num_rounds):\n",
    "    H = modifier.perturb_graph(perturb_type, num_to_remove, offset=i)\n",
    "    Hsparse = nx.spanner(H,3,seed=1)\n",
    "    prop = GraphProperties.get_graph_property(Hsparse, graph_property[0])\n",
    "    print(prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run with BETWEENNESS CENTRALITY and ADDING EDGES (randomly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betweenness Centrality  of the spanner of unperturbed graph\n",
      "0.002154876007644326 \n",
      "\n",
      "Betweenness Centrality  of the spanner of perturbed graph\n",
      "Perturbation:  100  edges are randomly added\n",
      "0.002018567414860488\n",
      "0.0020629933198904877\n",
      "0.002023189610997349\n",
      "0.00205078277267387\n",
      "0.002033032688717298\n"
     ]
    }
   ],
   "source": [
    "graph_property = GraphProperties.BETWEENNESS_CENTRALITY\n",
    "perturb_type = GraphModifier.ADD_RANDOM\n",
    "\n",
    "# Sparsify unperturbed graph and print property\n",
    "Gsparse = nx.spanner(G,3,seed=1)\n",
    "prop = GraphProperties.get_graph_property(Gsparse, graph_property[0])\n",
    "print(graph_property[1], \" of the spanner of unperturbed graph\")\n",
    "print(prop, '\\n')\n",
    "\n",
    "# Perturb graph, then sparsify, then print property\n",
    "num_trials = 5\n",
    "num_edges = 100\n",
    "print(graph_property[1], \" of the spanner of perturbed graph\")\n",
    "print(\"Perturbation: \", num_edges, \" edges are randomly added\")\n",
    "modifier = GraphModifier(G)\n",
    "for i in range(num_trials):\n",
    "    H = modifier.perturb_graph(perturb_type, num_edges)\n",
    "    Hsparse = nx.spanner(H,3,seed=7)\n",
    "    prop = GraphProperties.get_graph_property(Hsparse, graph_property[0])\n",
    "    print(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
